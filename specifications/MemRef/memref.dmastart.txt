//===----------------------------------------------------------------------===//
// DmaStartOp
//===----------------------------------------------------------------------===//

def MemRef_DmaStartOp : MemRef_Op<"dma_start"> {
  let summary = "non-blocking DMA operation that starts a transfer";
  let description = [{
    Syntax:

    ```
    operation ::= `memref.dma_start` ssa-use`[`ssa-use-list`]` `,`
                   ssa-use`[`ssa-use-list`]` `,` ssa-use `,`
                   ssa-use`[`ssa-use-list`]` (`,` ssa-use `,` ssa-use)?
                  `:` memref-type `,` memref-type `,` memref-type
    ```

    DmaStartOp starts a non-blocking DMA operation that transfers data from a
    source memref to a destination memref. The source and destination memref
    need not be of the same dimensionality, but need to have the same elemental
    type. The operands include the source and destination memref's each followed
    by its indices, size of the data transfer in terms of the number of elements
    (of the elemental type of the memref), a tag memref with its indices, and
    optionally at the end, a stride and a number_of_elements_per_stride
    arguments. The tag location is used by a DmaWaitOp to check for completion.
    The indices of the source memref, destination memref, and the tag memref
    have the same restrictions as any load/store. The optional stride arguments
    should be of 'index' type, and specify a stride for the slower memory space
    (memory space with a lower memory space id), transferring chunks of
    number_of_elements_per_stride every stride until %num_elements are
    transferred. Either both or no stride arguments should be specified. If the
    source and destination locations overlap the behavior of this operation is
    not defined.

    For example, a DmaStartOp operation that transfers 256 elements of a memref
    '%src' in memory space 0 at indices [%i, %j] to memref '%dst' in memory
    space 1 at indices [%k, %l], would be specified as follows:

    ```mlir
    %num_elements = arith.constant 256
    %idx = arith.constant 0 : index
    %tag = memref.alloc() : memref<1 x i32, affine_map<(d0) -> (d0)>, 4>
    dma_start %src[%i, %j], %dst[%k, %l], %num_elements, %tag[%idx] :
      memref<40 x 128 x f32>, affine_map<(d0) -> (d0)>, 0>,
      memref<2 x 1024 x f32>, affine_map<(d0) -> (d0)>, 1>,
      memref<1 x i32>, affine_map<(d0) -> (d0)>, 2>
    ```

    If %stride and %num_elt_per_stride are specified, the DMA is expected to
    transfer %num_elt_per_stride elements every %stride elements apart from
    memory space 0 until %num_elements are transferred.

    ```mlir
    dma_start %src[%i, %j], %dst[%k, %l], %num_elements, %tag[%idx], %stride,
              %num_elt_per_stride :
    ```

    * TODO: add additional operands to allow source and destination striding, and
    multiple stride levels.
    * TODO: Consider replacing src/dst memref indices with view memrefs.
  }];
  let arguments = (ins Variadic<AnyType>:$operands);

  let builders = [
    OpBuilder<(ins "Value":$srcMemRef, "ValueRange":$srcIndices,
                   "Value":$destMemRef, "ValueRange":$destIndices,
                   "Value":$numElements, "Value":$tagMemRef,
                   "ValueRange":$tagIndices, CArg<"Value", "{}">:$stride,
                   CArg<"Value", "{}">:$elementsPerStride)>
  ];

  let extraClassDeclaration = [{
    // Returns the source MemRefType for this DMA operation.
    Value getSrcMemRef() { return getOperand(0); }
    OpOperand &getSrcMemRefMutable() { return getOperation()->getOpOperand(0); }
    // Returns the rank (number of indices) of the source MemRefType.
    unsigned getSrcMemRefRank() {
      return ::llvm::cast<MemRefType>(getSrcMemRef().getType()).getRank();
    }
    // Returns the source memref indices for this DMA operation.
    operand_range getSrcIndices() {
      return {(*this)->operand_begin() + 1,
              (*this)->operand_begin() + 1 + getSrcMemRefRank()};
    }

    // Returns the destination MemRefType for this DMA operations.
    Value getDstMemRef() { return getOperand(1 + getSrcMemRefRank()); }
    OpOperand &getDstMemRefMutable() { return getOperation()->getOpOperand(1 + getSrcMemRefRank()); }
    // Returns the rank (number of indices) of the destination MemRefType.
    unsigned getDstMemRefRank() {
      return ::llvm::cast<MemRefType>(getDstMemRef().getType()).getRank();
    }
    unsigned getSrcMemorySpace() {
      return ::llvm::cast<MemRefType>(getSrcMemRef().getType()).getMemorySpaceAsInt();
    }
    unsigned getDstMemorySpace() {
      return ::llvm::cast<MemRefType>(getDstMemRef().getType()).getMemorySpaceAsInt();
    }

    // Returns the destination memref indices for this DMA operation.
    operand_range getDstIndices() {
      return {(*this)->operand_begin() + 1 + getSrcMemRefRank() + 1,
              (*this)->operand_begin() + 1 + getSrcMemRefRank() + 1 +
                  getDstMemRefRank()};
    }

    // Returns the number of elements being transferred by this DMA operation.
    Value getNumElements() {
      return getOperand(1 + getSrcMemRefRank() + 1 + getDstMemRefRank());
    }

    // Returns the Tag MemRef for this DMA operation.
    Value getTagMemRef() {
      return getOperand(1 + getSrcMemRefRank() + 1 + getDstMemRefRank() + 1);
    }
    OpOperand &getTagMemRefMutable() {
      return getOperation()->getOpOperand(1 + getSrcMemRefRank() + 1 + getDstMemRefRank() + 1);
    }

    // Returns the rank (number of indices) of the tag MemRefType.
    unsigned getTagMemRefRank() {
      return ::llvm::cast<MemRefType>(getTagMemRef().getType()).getRank();
    }

    // Returns the tag memref index for this DMA operation.
    operand_range getTagIndices() {
      unsigned tagIndexStartPos =
          1 + getSrcMemRefRank() + 1 + getDstMemRefRank() + 1 + 1;
      return {(*this)->operand_begin() + tagIndexStartPos,
              (*this)->operand_begin() + tagIndexStartPos + getTagMemRefRank()};
    }

    /// Returns true if this is a DMA from a faster memory space to a slower
    /// one.
    bool isDestMemorySpaceFaster() {
      return (getSrcMemorySpace() < getDstMemorySpace());
    }

    /// Returns true if this is a DMA from a slower memory space to a faster
    /// one.
    bool isSrcMemorySpaceFaster() {
      // Assumes that a lower number is for a slower memory space.
      return (getDstMemorySpace() < getSrcMemorySpace());
    }

    /// Given a DMA start operation, returns the operand position of either the
    /// source or destination memref depending on the one that is at the higher
    /// level of the memory hierarchy. Asserts failure if neither is true.
    unsigned getFasterMemPos() {
      assert(isSrcMemorySpaceFaster() || isDestMemorySpaceFaster());
      return isSrcMemorySpaceFaster() ? 0 : getSrcMemRefRank() + 1;
    }

    bool isStrided() {
      return getNumOperands() != 1 + getSrcMemRefRank() + 1 +
                                 getDstMemRefRank() + 1 + 1 +
                                 getTagMemRefRank();
    }

    Value getStride() {
      if (!isStrided())
        return nullptr;
      return getOperand(getNumOperands() - 1 - 1);
    }

    Value getNumElementsPerStride() {
      if (!isStrided())
        return nullptr;
      return getOperand(getNumOperands() - 1);
    }

    void getEffects(
        SmallVectorImpl<SideEffects::EffectInstance<MemoryEffects::Effect>> &
        effects) {
      effects.emplace_back(MemoryEffects::Read::get(), &getSrcMemRefMutable(),
                           SideEffects::DefaultResource::get());
      effects.emplace_back(MemoryEffects::Write::get(), &getDstMemRefMutable(),
                           SideEffects::DefaultResource::get());
      effects.emplace_back(MemoryEffects::Read::get(), &getTagMemRefMutable(),
                           SideEffects::DefaultResource::get());
    }
  }];
  let hasCustomAssemblyFormat = 1;
  let hasFolder = 1;
  let hasVerifier = 1;
}

